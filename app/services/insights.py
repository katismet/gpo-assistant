# app/services/insights.py
"""AI-—Å–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–∞."""

import os
import datetime as dt
import logging
from typing import Optional
import httpx
from dotenv import load_dotenv

from app.services.w6_alerts import (
    list_shifts_by_date,
    list_resources_by_shift,
    list_timesheets_by_shift,
    calc_resource_money,
    calc_timesheet_hours,
    calc_eff
)
from app.bitrix_field_map import resolve_code

load_dotenv()

log = logging.getLogger("gpo.insights")

# –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ config (—Å fallback –Ω–∞ os.getenv)
try:
    from app.config import get_settings
    settings = get_settings()
    OPENAI_API_KEY = settings.OPENAI_API_KEY or os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL = settings.OPENAI_MODEL or os.getenv("OPENAI_MODEL", "gpt-4o-mini")
except:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")


async def collect_kpis(date: dt.date) -> dict:
    """–°–æ–±—Ä–∞—Ç—å KPI –ø–æ —Å–º–µ–Ω–∞–º –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É."""
    shifts = await list_shifts_by_date(date)
    
    kpis = {
        "date": date.isoformat(),
        "shifts": [],
        "total_fact": 0.0,
        "total_hours": 0.0,
        "total_plan": 0.0,
        "shift_count": 0,
    }
    
    f_plan = resolve_code("–°–º–µ–Ω–∞", "UF_PLAN_TOTAL")
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –ø–æ–ª–µ–π –≤ –æ–±–æ–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
    def _get_field_value(item: dict, field_upper: str) -> any:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è –∏–∑ –∑–∞–ø–∏—Å–∏ Bitrix, –ø—Ä–æ–≤–µ—Ä—è—è –æ–±–∞ —Ñ–æ—Ä–º–∞—Ç–∞."""
        from app.bitrix_field_map import upper_to_camel
        value = item.get(field_upper)
        if value is None:
            value = item.get(upper_to_camel(field_upper))
        return value
    
    for s in shifts:
        sid = s["id"]
        resources = await list_resources_by_shift(sid)
        timesheets = await list_timesheets_by_shift(sid)
        
        fact = calc_resource_money(resources)
        hours = calc_timesheet_hours(timesheets)
        plan = float(_get_field_value(s, f_plan) or 0)
        
        eff_raw, eff_final = calc_eff(plan, fact)
        
        kpis["shifts"].append({
            "shift_id": sid,
            "fact": fact,
            "hours": hours,
            "plan": plan,
            "eff_final": eff_final
        })
        
        kpis["total_fact"] += fact
        kpis["total_hours"] += hours
        kpis["total_plan"] += plan
        kpis["shift_count"] += 1
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    if kpis["shift_count"] > 0:
        kpis["avg_eff"] = sum(s["eff_final"] for s in kpis["shifts"]) / kpis["shift_count"]
    else:
        kpis["avg_eff"] = 0.0
    
    return kpis


def _prompt_from_kpis(today: dict, yesterday: Optional[dict] = None) -> str:
    """–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç –∏–∑ KPI –¥–∞–Ω–Ω—ã—Ö."""
    lines = []
    lines.append(f"üìä –°–≤–æ–¥–∫–∞ –∑–∞ {today['date']}")
    lines.append(f"–°–º–µ–Ω: {today['shift_count']}")
    lines.append(f"–§–∞–∫—Ç: {today['total_fact']:.2f} —Ä—É–±.")
    lines.append(f"–ß–∞—Å—ã: {today['total_hours']:.2f} —á.")
    lines.append(f"–ü–ª–∞–Ω: {today['total_plan']:.2f} —Ä—É–±.")
    lines.append(f"–°—Ä–µ–¥–Ω—è—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {today['avg_eff']:.2%}")
    
    if yesterday:
        diff_fact = today["total_fact"] - yesterday["total_fact"]
        diff_hours = today["total_hours"] - yesterday["total_hours"]
        diff_plan = today["total_plan"] - yesterday["total_plan"]
        diff_eff = today["avg_eff"] - yesterday.get("avg_eff", 0)
        
        lines.append(f"\nüìà –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤—á–µ—Ä–∞:")
        lines.append(f"–§–∞–∫—Ç: {diff_fact:+.2f} —Ä—É–±. ({diff_fact/yesterday['total_fact']*100:+.1f}%)" if yesterday['total_fact'] > 0 else f"–§–∞–∫—Ç: {diff_fact:+.2f} —Ä—É–±.")
        lines.append(f"–ß–∞—Å—ã: {diff_hours:+.2f} —á.")
        lines.append(f"–ü–ª–∞–Ω: {diff_plan:+.2f} —Ä—É–±.")
        lines.append(f"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {diff_eff:+.2%}")
    
    # –¢–æ–ø-3 —Å–º–µ–Ω—ã –ø–æ —Ñ–∞–∫—Ç—É
    if today["shifts"]:
        top_shifts = sorted(today["shifts"], key=lambda x: x["fact"], reverse=True)[:3]
        lines.append(f"\nüîù –¢–æ–ø-3 —Å–º–µ–Ω—ã –ø–æ —Ñ–∞–∫—Ç—É:")
        for i, s in enumerate(top_shifts, 1):
            lines.append(f"{i}. –°–º–µ–Ω–∞ #{s['shift_id']}: {s['fact']:.2f} —Ä—É–±. (—ç—Ñ—Ñ. {s['eff_final']:.2%})")
    
    return "\n".join(lines)


async def generate_insights(today: dict, yesterday: Optional[dict] = None) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å AI-–∏–Ω—Å–∞–π—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ KPI."""
    if not OPENAI_API_KEY:
        # Fallback ‚Äî –ø—Ä–æ—Å—Ç–∞—è —Ä—É—á–Ω–∞—è —Å–≤–æ–¥–∫–∞ –±–µ–∑ LLM
        log.warning("OPENAI_API_KEY not set, using fallback insights")
        return _prompt_from_kpis(today, yesterday) + "\n\n(ü§ñ AI-–∞–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª—é—á—ë–Ω: –Ω–µ —É–∫–∞–∑–∞–Ω OPENAI_API_KEY)"
    
    prompt = (
        "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏—Ä–º—ã. "
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ —Å–º–µ–Ω–∞–º –∏ —Ä–µ—Å—É—Ä—Å–∞–º: —Å—Ä–∞–≤–Ω–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –¥–Ω—ë–º, "
        "–æ–±–æ–∑–Ω–∞—á—å –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π (–≥–∏–ø–æ—Ç–µ–∑—ã) –∏ –¥–∞–π 3‚Äì5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π. "
        "–ö—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n\n" + _prompt_from_kpis(today, yesterday)
    )
    
    try:
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI (HTTP)
        async with httpx.AsyncClient(timeout=60.0) as client:
            r = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": OPENAI_MODEL,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.2,
                    "max_tokens": 1000
                }
            )
            r.raise_for_status()
            data = r.json()
            
        result = data["choices"][0]["message"]["content"].strip()
        log.info(f"Generated insights for {today['date']}")
        return result
        
    except httpx.HTTPStatusError as e:
        log.error(f"OpenAI API error: {e.response.status_code} - {e.response.text}")
        return _prompt_from_kpis(today, yesterday) + f"\n\n‚ùå –û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {e.response.status_code}"
    except Exception as e:
        log.error(f"Error generating insights: {e}", exc_info=True)
        return _prompt_from_kpis(today, yesterday) + f"\n\n‚ùå –û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {e}"

